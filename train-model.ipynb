{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30733,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-07-05T21:02:40.213353Z","iopub.execute_input":"2024-07-05T21:02:40.214822Z","iopub.status.idle":"2024-07-05T21:02:41.481916Z","shell.execute_reply.started":"2024-07-05T21:02:40.214773Z","shell.execute_reply":"2024-07-05T21:02:41.480522Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"!pip install transformers datasets evaluate rouge_score","metadata":{"execution":{"iopub.status.busy":"2024-07-05T21:32:40.913381Z","iopub.execute_input":"2024-07-05T21:32:40.914026Z","iopub.status.idle":"2024-07-05T21:32:57.640930Z","shell.execute_reply.started":"2024-07-05T21:32:40.913994Z","shell.execute_reply":"2024-07-05T21:32:57.639956Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.41.2)\nRequirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (2.19.2)\nCollecting evaluate\n  Downloading evaluate-0.4.2-py3-none-any.whl.metadata (9.3 kB)\nCollecting rouge_score\n  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.13.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.23.2)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.12.25)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.32.3)\nRequirement already satisfied: tokenizers<0.20,>=0.19 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.19.1)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.3)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.4)\nRequirement already satisfied: pyarrow>=12.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (14.0.2)\nRequirement already satisfied: pyarrow-hotfix in /opt/conda/lib/python3.10/site-packages (from datasets) (0.6)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.8)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets) (2.2.1)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.16)\nRequirement already satisfied: fsspec<=2024.3.1,>=2023.1.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<=2024.3.1,>=2023.1.0->datasets) (2024.3.1)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.9.1)\nRequirement already satisfied: absl-py in /opt/conda/lib/python3.10/site-packages (from rouge_score) (1.4.0)\nRequirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (from rouge_score) (3.2.4)\nRequirement already satisfied: six>=1.14.0 in /opt/conda/lib/python3.10/site-packages (from rouge_score) (1.16.0)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (23.2.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.4)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.3)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (4.9.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.1.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2024.2.2)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.4)\nDownloading evaluate-0.4.2-py3-none-any.whl (84 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: rouge_score\n  Building wheel for rouge_score (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for rouge_score: filename=rouge_score-0.1.2-py3-none-any.whl size=24934 sha256=7442e68461e442c77eef3c39f84413a12dcfec003c0353ac361d61f385f0aa44\n  Stored in directory: /root/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\nSuccessfully built rouge_score\nInstalling collected packages: rouge_score, evaluate\nSuccessfully installed evaluate-0.4.2 rouge_score-0.1.2\n","output_type":"stream"}]},{"cell_type":"code","source":"from huggingface_hub import notebook_login\n\nnotebook_login()","metadata":{"execution":{"iopub.status.busy":"2024-07-05T21:33:03.107271Z","iopub.execute_input":"2024-07-05T21:33:03.107617Z","iopub.status.idle":"2024-07-05T21:33:03.397306Z","shell.execute_reply.started":"2024-07-05T21:33:03.107589Z","shell.execute_reply":"2024-07-05T21:33:03.396494Z"},"trusted":true},"execution_count":2,"outputs":[{"output_type":"display_data","data":{"text/plain":"VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"069d3c283cc34e2cadb8ae9cfc9df558"}},"metadata":{}}]},{"cell_type":"code","source":"from datasets import load_dataset\n\ndata = load_dataset('tasksource/seahorse_summarization_evaluation', split=\"train[:1%]\")\ndata = data.train_test_split(test_size=0.1)","metadata":{"execution":{"iopub.status.busy":"2024-07-05T22:16:29.031415Z","iopub.execute_input":"2024-07-05T22:16:29.031794Z","iopub.status.idle":"2024-07-05T22:16:30.894883Z","shell.execute_reply.started":"2024-07-05T22:16:29.031766Z","shell.execute_reply":"2024-07-05T22:16:30.894099Z"},"trusted":true},"execution_count":63,"outputs":[]},{"cell_type":"code","source":"from transformers import AutoTokenizer\n\ncheckpoint = \"google-t5/t5-small\"\ntokenizer = AutoTokenizer.from_pretrained(checkpoint)","metadata":{"execution":{"iopub.status.busy":"2024-07-05T21:57:06.478270Z","iopub.execute_input":"2024-07-05T21:57:06.479183Z","iopub.status.idle":"2024-07-05T21:57:06.655675Z","shell.execute_reply.started":"2024-07-05T21:57:06.479149Z","shell.execute_reply":"2024-07-05T21:57:06.654865Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"prefix = \"summarize: \"\n\ndef preprocess_function(examples):\n    inputs = [prefix + doc for doc in examples[\"article\"]]\n    model_inputs = tokenizer(inputs, max_length=1024, truncation=True)\n    \n    labels = tokenizer(text_target=examples[\"summary\"], max_length=128, truncation=True)\n    \n    model_inputs[\"label\"] = labels[\"input_ids\"]\n    return model_inputs","metadata":{"execution":{"iopub.status.busy":"2024-07-05T21:36:56.427113Z","iopub.execute_input":"2024-07-05T21:36:56.427951Z","iopub.status.idle":"2024-07-05T21:36:56.433922Z","shell.execute_reply.started":"2024-07-05T21:36:56.427917Z","shell.execute_reply":"2024-07-05T21:36:56.432704Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"tokenized_data = data.map(preprocess_function, batched=True)","metadata":{"execution":{"iopub.status.busy":"2024-07-05T22:16:50.091863Z","iopub.execute_input":"2024-07-05T22:16:50.092689Z","iopub.status.idle":"2024-07-05T22:16:54.648253Z","shell.execute_reply.started":"2024-07-05T22:16:50.092640Z","shell.execute_reply":"2024-07-05T22:16:54.647405Z"},"trusted":true},"execution_count":65,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/3013 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e75b353a883b471385d061b2d53cb98f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/335 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"32f2724ae43e454296f0728eb555c15f"}},"metadata":{}}]},{"cell_type":"code","source":"from transformers import DataCollatorForSeq2Seq\n\ndata_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=checkpoint)","metadata":{"execution":{"iopub.status.busy":"2024-07-05T21:58:26.970926Z","iopub.execute_input":"2024-07-05T21:58:26.971799Z","iopub.status.idle":"2024-07-05T21:58:26.975758Z","shell.execute_reply.started":"2024-07-05T21:58:26.971764Z","shell.execute_reply":"2024-07-05T21:58:26.974873Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"import evaluate\n\nrouge = evaluate.load(\"rouge\")","metadata":{"execution":{"iopub.status.busy":"2024-07-05T21:52:57.694569Z","iopub.execute_input":"2024-07-05T21:52:57.694925Z","iopub.status.idle":"2024-07-05T21:52:58.699330Z","shell.execute_reply.started":"2024-07-05T21:52:57.694899Z","shell.execute_reply":"2024-07-05T21:52:58.698585Z"},"trusted":true},"execution_count":16,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/6.27k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f3eb4dfc054c4a3d8817d4ea5fe6ac05"}},"metadata":{}}]},{"cell_type":"code","source":"import numpy as np\n\ndef compute_metrics(eval_pred):\n    predictions, labels = eval_pred\n    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n    \n    result = rouge.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True)\n    \n    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in predictions]\n    result[\"gen_len\"] = np.mean(prediction_lens)\n    \n    return {k: round(v, 4) for k, v in result.items()}","metadata":{"execution":{"iopub.status.busy":"2024-07-05T22:21:01.846310Z","iopub.execute_input":"2024-07-05T22:21:01.846674Z","iopub.status.idle":"2024-07-05T22:21:01.853812Z","shell.execute_reply.started":"2024-07-05T22:21:01.846631Z","shell.execute_reply":"2024-07-05T22:21:01.852845Z"},"trusted":true},"execution_count":67,"outputs":[]},{"cell_type":"code","source":"from transformers import AutoModelForSeq2SeqLM, Seq2SeqTrainingArguments, Seq2SeqTrainer\n\nmodel = AutoModelForSeq2SeqLM.from_pretrained(checkpoint)","metadata":{"execution":{"iopub.status.busy":"2024-07-05T21:54:00.495889Z","iopub.execute_input":"2024-07-05T21:54:00.496254Z","iopub.status.idle":"2024-07-05T21:54:02.430450Z","shell.execute_reply.started":"2024-07-05T21:54:00.496224Z","shell.execute_reply":"2024-07-05T21:54:02.429545Z"},"trusted":true},"execution_count":20,"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"451b245c4a484221897d8fc95d8b87bb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/242M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2cc7cbcb09df44ec9de0be18b3bcbdaa"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3318c88f4f93462eb33008bfa48431cc"}},"metadata":{}}]},{"cell_type":"code","source":"import wandb\n\nwandb.init(mode = \"disabled\")","metadata":{"execution":{"iopub.status.busy":"2024-07-05T21:54:18.762494Z","iopub.execute_input":"2024-07-05T21:54:18.763246Z","iopub.status.idle":"2024-07-05T21:54:20.034583Z","shell.execute_reply.started":"2024-07-05T21:54:18.763215Z","shell.execute_reply":"2024-07-05T21:54:20.033694Z"},"trusted":true},"execution_count":21,"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":""},"metadata":{}}]},{"cell_type":"code","source":"training_args = Seq2SeqTrainingArguments(\n    output_dir = \"summarization_model\",\n    eval_strategy=\"epoch\",\n    learning_rate = 2e-5,\n    per_device_train_batch_size = 8,\n    per_device_eval_batch_size = 8,\n    weight_decay = 0.01,\n    save_total_limit = 3,\n    num_train_epochs = 4,\n    predict_with_generate = True,\n    fp16 = True,\n    push_to_hub = True\n)\n\ntrainer = Seq2SeqTrainer(\n    model = model,\n    args = training_args,\n    train_dataset = tokenized_data[\"train\"],\n    eval_dataset = tokenized_data[\"test\"],\n    tokenizer = tokenizer,\n    data_collator = data_collator,\n    compute_metrics = compute_metrics\n)\n\ntrainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-07-05T22:21:06.399334Z","iopub.execute_input":"2024-07-05T22:21:06.400126Z","iopub.status.idle":"2024-07-05T22:34:57.735843Z","shell.execute_reply.started":"2024-07-05T22:21:06.400086Z","shell.execute_reply":"2024-07-05T22:34:57.734904Z"},"trusted":true},"execution_count":68,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='1508' max='1508' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [1508/1508 13:49, Epoch 4/4]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Rouge1</th>\n      <th>Rouge2</th>\n      <th>Rougel</th>\n      <th>Rougelsum</th>\n      <th>Gen Len</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>No log</td>\n      <td>1.648781</td>\n      <td>0.171100</td>\n      <td>0.054500</td>\n      <td>0.144100</td>\n      <td>0.144500</td>\n      <td>18.513400</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>1.851000</td>\n      <td>1.605939</td>\n      <td>0.174300</td>\n      <td>0.056500</td>\n      <td>0.147800</td>\n      <td>0.147700</td>\n      <td>18.513400</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>1.789900</td>\n      <td>1.585880</td>\n      <td>0.175800</td>\n      <td>0.057500</td>\n      <td>0.146300</td>\n      <td>0.145900</td>\n      <td>18.543300</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>1.752400</td>\n      <td>1.580544</td>\n      <td>0.178600</td>\n      <td>0.057600</td>\n      <td>0.148800</td>\n      <td>0.148000</td>\n      <td>18.564200</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1168: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1168: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1168: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1168: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n  warnings.warn(\n","output_type":"stream"},{"execution_count":68,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=1508, training_loss=1.7980128517201472, metrics={'train_runtime': 830.0669, 'train_samples_per_second': 14.519, 'train_steps_per_second': 1.817, 'total_flos': 3241104134897664.0, 'train_loss': 1.7980128517201472, 'epoch': 4.0})"},"metadata":{}}]},{"cell_type":"code","source":"trainer.push_to_hub()","metadata":{"execution":{"iopub.status.busy":"2024-07-05T22:35:09.381738Z","iopub.execute_input":"2024-07-05T22:35:09.382201Z","iopub.status.idle":"2024-07-05T22:35:22.835601Z","shell.execute_reply.started":"2024-07-05T22:35:09.382158Z","shell.execute_reply":"2024-07-05T22:35:22.834730Z"},"trusted":true},"execution_count":69,"outputs":[{"output_type":"display_data","data":{"text/plain":"events.out.tfevents.1720218067.65470d195559.34.11:   0%|          | 0.00/8.90k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dc24f4803b2d4fffb829c7483d0d1eed"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/242M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3a545ffd1c564a51b84989f1e9abff4e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Upload 2 LFS files:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2be3d99ad80f4e17a649d9fb534b060d"}},"metadata":{}},{"execution_count":69,"output_type":"execute_result","data":{"text/plain":"CommitInfo(commit_url='https://huggingface.co/dross20/summarization_model/commit/671ee3001466d6f68c7a612dce2c29f34c63f05a', commit_message='End of training', commit_description='', oid='671ee3001466d6f68c7a612dce2c29f34c63f05a', pr_url=None, pr_revision=None, pr_num=None)"},"metadata":{}}]},{"cell_type":"code","source":"from transformers import pipeline\n\nsummarize = pipeline(\"summarization\")","metadata":{"execution":{"iopub.status.busy":"2024-07-05T22:43:52.428144Z","iopub.execute_input":"2024-07-05T22:43:52.428865Z","iopub.status.idle":"2024-07-05T22:44:00.028159Z","shell.execute_reply.started":"2024-07-05T22:43:52.428830Z","shell.execute_reply":"2024-07-05T22:44:00.027355Z"},"trusted":true},"execution_count":76,"outputs":[{"name":"stderr","text":"No model was supplied, defaulted to sshleifer/distilbart-cnn-12-6 and revision a4f8f3e (https://huggingface.co/sshleifer/distilbart-cnn-12-6).\nUsing a pipeline without specifying a model name and revision in production is not recommended.\n/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.80k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7692060d1df543c3b711b5c7b89a2517"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/1.22G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"484dfb65f1714f9a8263314a2aa0a7fa"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n  return self.fget.__get__(instance, owner)()\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6154fbb969bc4446a5c4e60ba8004233"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cbdf135fad4448d59f0f78c36262aeb6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1982cb37d9b74486afa85952e1e3d944"}},"metadata":{}}]},{"cell_type":"code","source":"summarize(\"Planetarium: A Rigorous Benchmark for Translating Text to Structured Planning Languages: Many recent works have explored using language models for planning problems. One line of research focuses on translating natural language descriptions of planning tasks into structured planning languages, such as the planning domain definition language (PDDL). While this approach is promising, accurately measuring the quality of generated PDDL code continues to pose significant challenges. First, generated PDDL code is typically evaluated using planning validators that check whether the problem can be solved with a planner. This method is insufficient because a language model might generate valid PDDL code that does not align with the natural language description of the task. Second, existing evaluation sets often have natural language descriptions of the planning task that closely resemble the ground truth PDDL, reducing the challenge of the task. To bridge this gap, we introduce \\benchmarkName, a benchmark designed to evaluate language models' ability to generate PDDL code from natural language descriptions of planning tasks. We begin by creating a PDDL equivalence algorithm that rigorously evaluates the correctness of PDDL code generated by language models by flexibly comparing it against a ground truth PDDL. Then, we present a dataset of 132,037 text-to-PDDL pairs across 13 different tasks, with varying levels of difficulty. Finally, we evaluate several API-access and open-weight language models that reveal this task's complexity. For example, 87.6% of the PDDL problem descriptions generated by GPT-4o are syntactically parseable, 82.2% are valid, solve-able problems, but only 35.1% are semantically correct, highlighting the need for a more rigorous benchmark for this problem.\")","metadata":{"execution":{"iopub.status.busy":"2024-07-05T22:44:05.331775Z","iopub.execute_input":"2024-07-05T22:44:05.332362Z","iopub.status.idle":"2024-07-05T22:44:10.747521Z","shell.execute_reply.started":"2024-07-05T22:44:05.332333Z","shell.execute_reply":"2024-07-05T22:44:10.746364Z"},"trusted":true},"execution_count":77,"outputs":[{"execution_count":77,"output_type":"execute_result","data":{"text/plain":"[{'summary_text': \" Many recent works have explored using language models for planning problems, such as the planning domain definition language (PDDL) While this approach is promising, accurately measuring the quality of generated PDDL code continues to pose significant challenges . To bridge this gap, we introduce enchmarkName, a benchmark designed to evaluate language models' ability to generate .\"}]"},"metadata":{}}]}]}